{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools, copy, json, random, torch, timm, torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "from torchvision import datasets, transforms\n",
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "\n",
    "import pandas as pd, pprint, json\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    # --- utils ---\n",
    "    seed          = 42\n",
    "    train         = True\n",
    "    inference     = False\n",
    "\n",
    "    # --- data ---\n",
    "    LABELS        = [\"Unripe\", \"Early Ripening\", \"Ripe\", \"Fully Ripe\", \"Overripe\"]\n",
    "    batch_size    = 32            # default 32 fits 299² on 8 GB GPU; tune in your grid search\n",
    "    img_size      = 299           # Inception V3 native input\n",
    "    num_classes   = len(LABELS)\n",
    "    input_channels= 3\n",
    "    mean          = (0.485, 0.456, 0.406)   # ImageNet\n",
    "    std           = (0.229, 0.224, 0.225)\n",
    "\n",
    "    # --- training ---\n",
    "    epochs        = 50\n",
    "\n",
    "    # --- optimiser / scheduler ---\n",
    "    loss_fn       = 'CrossEntropy'          # will be overridden by grid search\n",
    "    lr            = 0.0001                 # idem\n",
    "    scheduler     = 'ReduceOnPlateau'      # optional\n",
    "    min_lr        = 1e-6\n",
    "    optimizer     = 'Adam'\n",
    "    wd            = 1e-6\n",
    "    momentum      = 0.9\n",
    "    num_workers   = 2\n",
    "\n",
    "    # --- device ---\n",
    "    device        = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    # --- model ---\n",
    "    base_model    = 'inception_v3'          # torchvision name\n",
    "    weight        = 'IMAGENET1K_V1'         # matches torchvision tag\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting Up the Search Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "SEARCH = {\n",
    "    \"optimizer\": [\"Adam\", \"SGD\", \"Adagrad\"],\n",
    "    \"lr\"       : [1e-3, 5e-3, 1e-4],\n",
    "    \"loss_fn\"  : [\"CrossEntropy\", \"WeightedCrossEntropy\"],\n",
    "    \"batch_size\": [16, 32, 64]\n",
    "}\n",
    "\n",
    "def expand_grid(search_dict):\n",
    "    keys, values = zip(*search_dict.items())\n",
    "    for v in itertools.product(*values):\n",
    "        yield dict(zip(keys, v))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utility \n",
    "build → train → eval for one run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(cfg):\n",
    "    model = timm.create_model(cfg.base_model, pretrained=True, num_classes=cfg.num_classes)\n",
    "    return model.to(cfg.device)\n",
    "\n",
    "def make_criterion(cfg, class_count):\n",
    "    if cfg.loss_fn == \"CrossEntropy\":\n",
    "        return nn.CrossEntropyLoss()\n",
    "    elif cfg.loss_fn == \"WeightedCrossEntropy\":\n",
    "        # crude weight: 1 / freq\n",
    "        counts = torch.tensor(class_count, dtype=torch.float32)\n",
    "        weights = (1.0 / counts) * len(counts) / counts.sum()\n",
    "        return nn.CrossEntropyLoss(weight=weights.to(cfg.device))\n",
    "\n",
    "def make_optimizer(cfg, model):\n",
    "    if cfg.optimizer == \"Adam\":\n",
    "        return torch.optim.Adam(model.parameters(), lr=cfg.lr, weight_decay=cfg.wd)\n",
    "    if cfg.optimizer == \"SGD\":\n",
    "        return torch.optim.SGD(model.parameters(), lr=cfg.lr,\n",
    "                               momentum=cfg.momentum, weight_decay=cfg.wd)\n",
    "    if cfg.optimizer == \"Adagrad\":\n",
    "        return torch.optim.Adagrad(model.parameters(), lr=cfg.lr, weight_decay=cfg.wd)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Loop - Condensed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_CUDA = torch.cuda.is_available()\n",
    "scaler   = GradScaler(enabled=USE_CUDA)\n",
    "\n",
    "def train_one_epoch(model, loader, criterion, optimizer, scaler, device):\n",
    "    model.train()\n",
    "    loss_meter = 0\n",
    "    for X, y in loader:\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        with autocast(enabled=USE_CUDA):\n",
    "            logits = model(X)\n",
    "            loss   = criterion(logits, y)\n",
    "\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        loss_meter += loss.item() * X.size(0)\n",
    "\n",
    "    return loss_meter / len(loader.dataset)\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate(model, loader, device):\n",
    "    model.eval()\n",
    "    y_true, y_pred = [], []\n",
    "    for X, y in loader:\n",
    "        X = X.to(device)\n",
    "        logits = model(X)\n",
    "        y_true += y.tolist()\n",
    "        y_pred += logits.argmax(1).cpu().tolist()\n",
    "    return accuracy_score(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hook it All Together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "DATA_ROOT = Path(\"./data/processed_data/\")\n",
    "SEED = CFG.seed\n",
    "torch.manual_seed(SEED)\n",
    "random.seed(SEED)\n",
    "\n",
    "# constant transforms (resize to cfg.img_size)\n",
    "# From size 224x224 to 299x299 for suit InceptionV3\n",
    "train_tf = transforms.Compose([\n",
    "    transforms.Resize((CFG.img_size, CFG.img_size)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(20),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(CFG.mean, CFG.std)\n",
    "])\n",
    "val_tf = transforms.Compose([\n",
    "    transforms.Resize((CFG.img_size, CFG.img_size)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(CFG.mean, CFG.std)\n",
    "])\n",
    "\n",
    "full_ds = datasets.ImageFolder(DATA_ROOT, transform=train_tf)\n",
    "class_hist = Counter([y for _, y in full_ds])\n",
    "\n",
    "# simple 80 / 20 split\n",
    "val_len = int(0.2 * len(full_ds))\n",
    "train_len = len(full_ds) - val_len\n",
    "train_ds, val_ds = torch.utils.data.random_split(full_ds, [train_len, val_len])\n",
    "val_ds.dataset.transform = val_tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⟹ Run: {'optimizer': 'Adam', 'lr': 0.001, 'loss_fn': 'CrossEntropy', 'batch_size': 16}\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 22\u001b[39m\n\u001b[32m     20\u001b[39m best_val, best_epoch = \u001b[32m0.0\u001b[39m, -\u001b[32m1\u001b[39m\n\u001b[32m     21\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(cfg.epochs):\n\u001b[32m---> \u001b[39m\u001b[32m22\u001b[39m     _ = \u001b[43mtrain_one_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     23\u001b[39m \u001b[43m                        \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscaler\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     24\u001b[39m     val_acc = evaluate(model, val_loader, cfg.device)\n\u001b[32m     26\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m val_acc > best_val:\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 7\u001b[39m, in \u001b[36mtrain_one_epoch\u001b[39m\u001b[34m(model, loader, criterion, optimizer, scaler, device)\u001b[39m\n\u001b[32m      5\u001b[39m model.train()\n\u001b[32m      6\u001b[39m loss_meter = \u001b[32m0\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mloader\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mzero_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\1000304936.CORP\\Documents\\CDS521\\.venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:439\u001b[39m, in \u001b[36mDataLoader.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    437\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._iterator\n\u001b[32m    438\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m439\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\1000304936.CORP\\Documents\\CDS521\\.venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:387\u001b[39m, in \u001b[36mDataLoader._get_iterator\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    385\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    386\u001b[39m     \u001b[38;5;28mself\u001b[39m.check_worker_number_rationality()\n\u001b[32m--> \u001b[39m\u001b[32m387\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_MultiProcessingDataLoaderIter\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\1000304936.CORP\\Documents\\CDS521\\.venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:1040\u001b[39m, in \u001b[36m_MultiProcessingDataLoaderIter.__init__\u001b[39m\u001b[34m(self, loader)\u001b[39m\n\u001b[32m   1033\u001b[39m w.daemon = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m   1034\u001b[39m \u001b[38;5;66;03m# NB: Process.start() actually take some time as it needs to\u001b[39;00m\n\u001b[32m   1035\u001b[39m \u001b[38;5;66;03m#     start a process and pass the arguments over via a pipe.\u001b[39;00m\n\u001b[32m   1036\u001b[39m \u001b[38;5;66;03m#     Therefore, we only add a worker to self._workers list after\u001b[39;00m\n\u001b[32m   1037\u001b[39m \u001b[38;5;66;03m#     it started, so that we do not call .join() if program dies\u001b[39;00m\n\u001b[32m   1038\u001b[39m \u001b[38;5;66;03m#     before it starts, and __del__ tries to join but will get:\u001b[39;00m\n\u001b[32m   1039\u001b[39m \u001b[38;5;66;03m#     AssertionError: can only join a started process.\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1040\u001b[39m \u001b[43mw\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstart\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1041\u001b[39m \u001b[38;5;28mself\u001b[39m._index_queues.append(index_queue)\n\u001b[32m   1042\u001b[39m \u001b[38;5;28mself\u001b[39m._workers.append(w)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\Program Files\\Python311\\Lib\\multiprocessing\\process.py:121\u001b[39m, in \u001b[36mBaseProcess.start\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _current_process._config.get(\u001b[33m'\u001b[39m\u001b[33mdaemon\u001b[39m\u001b[33m'\u001b[39m), \\\n\u001b[32m    119\u001b[39m        \u001b[33m'\u001b[39m\u001b[33mdaemonic processes are not allowed to have children\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m    120\u001b[39m _cleanup()\n\u001b[32m--> \u001b[39m\u001b[32m121\u001b[39m \u001b[38;5;28mself\u001b[39m._popen = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_Popen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    122\u001b[39m \u001b[38;5;28mself\u001b[39m._sentinel = \u001b[38;5;28mself\u001b[39m._popen.sentinel\n\u001b[32m    123\u001b[39m \u001b[38;5;66;03m# Avoid a refcycle if the target function holds an indirect\u001b[39;00m\n\u001b[32m    124\u001b[39m \u001b[38;5;66;03m# reference to the process object (see bpo-30775)\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\Program Files\\Python311\\Lib\\multiprocessing\\context.py:224\u001b[39m, in \u001b[36mProcess._Popen\u001b[39m\u001b[34m(process_obj)\u001b[39m\n\u001b[32m    222\u001b[39m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[32m    223\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_Popen\u001b[39m(process_obj):\n\u001b[32m--> \u001b[39m\u001b[32m224\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_context\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_context\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mProcess\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_Popen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\Program Files\\Python311\\Lib\\multiprocessing\\context.py:336\u001b[39m, in \u001b[36mSpawnProcess._Popen\u001b[39m\u001b[34m(process_obj)\u001b[39m\n\u001b[32m    333\u001b[39m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[32m    334\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_Popen\u001b[39m(process_obj):\n\u001b[32m    335\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpopen_spawn_win32\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Popen\n\u001b[32m--> \u001b[39m\u001b[32m336\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mPopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\Program Files\\Python311\\Lib\\multiprocessing\\popen_spawn_win32.py:94\u001b[39m, in \u001b[36mPopen.__init__\u001b[39m\u001b[34m(self, process_obj)\u001b[39m\n\u001b[32m     92\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     93\u001b[39m     reduction.dump(prep_data, to_child)\n\u001b[32m---> \u001b[39m\u001b[32m94\u001b[39m     \u001b[43mreduction\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mto_child\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     95\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m     96\u001b[39m     set_spawning_popen(\u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\Program Files\\Python311\\Lib\\multiprocessing\\reduction.py:60\u001b[39m, in \u001b[36mdump\u001b[39m\u001b[34m(obj, file, protocol)\u001b[39m\n\u001b[32m     58\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdump\u001b[39m(obj, file, protocol=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m     59\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m'''Replacement for pickle.dump() using ForkingPickler.'''\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m60\u001b[39m     \u001b[43mForkingPickler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprotocol\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "results = []\n",
    "\n",
    "for hp in expand_grid(SEARCH):\n",
    "    cfg = copy.deepcopy(CFG)\n",
    "    for k, v in hp.items():\n",
    "        setattr(cfg, k, v)\n",
    "    print(\"⟹ Run:\", hp)\n",
    "\n",
    "    pin_mem = torch.cuda.is_available()\n",
    "    train_loader = DataLoader(train_ds, batch_size=cfg.batch_size,\n",
    "                              shuffle=True,  num_workers=cfg.num_workers, pin_memory=pin_mem)\n",
    "    val_loader   = DataLoader(val_ds,   batch_size=cfg.batch_size,\n",
    "                              shuffle=False, num_workers=cfg.num_workers, pin_memory=pin_mem)\n",
    "\n",
    "    model      = build_model(cfg)\n",
    "    criterion  = make_criterion(cfg, [class_hist[i] for i in range(cfg.num_classes)])\n",
    "    optimizer  = make_optimizer(cfg, model)\n",
    "    scaler     = GradScaler(enabled=torch.cuda.is_available())\n",
    "\n",
    "    best_val, best_epoch = 0.0, -1\n",
    "    for epoch in range(cfg.epochs):\n",
    "        _ = train_one_epoch(model, train_loader, criterion,\n",
    "                            optimizer, scaler, cfg.device)\n",
    "        val_acc = evaluate(model, val_loader, cfg.device)\n",
    "\n",
    "        if val_acc > best_val:\n",
    "            best_val, best_epoch = val_acc, epoch\n",
    "\n",
    "        # early-stop after 8 epochs with no gain\n",
    "        if epoch - best_epoch > 8:\n",
    "            break\n",
    "\n",
    "    results.append({**hp, \"val_acc\": best_val})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = pd.DataFrame(results).sort_values(\"val_acc\", ascending=False)\n",
    "print(df.head(10))\n",
    "best_cfg = df.iloc[0].to_dict()\n",
    "print(\"\\nBest combo:\", best_cfg)\n",
    "# df.to_csv(\"search_results.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# -------------------------------\n",
    "# 1) list-of-dicts  ➜  DataFrame\n",
    "# -------------------------------\n",
    "df = pd.DataFrame(results)           # results must still be in memory\n",
    "df_sorted = df.sort_values(\"val_acc\", ascending=False).reset_index(drop=True)\n",
    "\n",
    "# --------------------------------\n",
    "# 2) show the full table in Jupyter\n",
    "# --------------------------------\n",
    "display(df_sorted)\n",
    "\n",
    "\n",
    "# --------------------------------\n",
    "# 4) quick bar chart of top-N runs\n",
    "# --------------------------------\n",
    "top_n = 10\n",
    "plt.figure(figsize=(12, 6))\n",
    "bars = plt.bar(range(top_n), df_sorted[\"val_acc\"][:top_n])\n",
    "plt.xticks(range(top_n),\n",
    "           [f\"{r.optimizer}|lr={r.lr}|{r.loss_fn}|bs{r.batch_size}\"\n",
    "            for _, r in df_sorted.head(top_n).iterrows()],\n",
    "           rotation=45, ha=\"right\")\n",
    "plt.ylabel(\"Validation accuracy\")\n",
    "plt.title(f\"Top {top_n} hyper-parameter runs\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# --------------------------------\n",
    "# 5) print the single best config\n",
    "# --------------------------------\n",
    "best = df_sorted.iloc[0]\n",
    "print(\"\\n Best run:\")\n",
    "print(best.to_string())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
